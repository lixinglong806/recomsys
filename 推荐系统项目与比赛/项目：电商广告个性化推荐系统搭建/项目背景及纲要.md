



# 项目一、个性化电商广告推荐系统介绍

## 1 数据集介绍

- 京东提供一个京东商城展示广告点击率预估数据集

  

- 原始样本骨架raw_sample

  京东商城网站中随机抽样了114万用户8天内的广告展示/点击日志（2600万条记录），构成原始的样本骨架。 字段说明如下：

  1. user_id：脱敏过的用户ID；
  2. adgroup_id：脱敏过的广告单元ID；
  3. time_stamp：时间戳；
  4. pid：资源位；
  5. noclk：为1代表没有点击；为0代表点击；
  6. clk：为0代表没有点击；为1代表点击；

  用前面7天的做训练样本（20170506-20170512），用第8天的做测试样本（20170513）

- 广告基本信息表ad_feature

  本数据集涵盖了raw_sample中全部广告的基本信息(约80万条目)。字段说明如下：

  1. adgroup_id：脱敏过的广告ID；
  2. cate_id：脱敏过的商品类目ID；
  3. campaign_id：脱敏过的广告计划ID；
  4. customer_id: 脱敏过的广告主ID；
  5. brand_id：脱敏过的品牌ID；
  6. price: 宝贝的价格

  其中一个广告ID对应一个商品（宝贝），一个宝贝属于一个类目，一个宝贝属于一个品牌。

- 用户基本信息表user_profile

  本数据集涵盖了raw_sample中全部用户的基本信息(约100多万用户)。字段说明如下：

  1. userid：脱敏过的用户ID；
  2. cms_segid：微群ID；
  3. cms_group_id：cms_group_id；
  4. final_gender_code：性别 1:男,2:女；
  5. age_level：年龄层次； 1234
  6. pvalue_level：消费档次，1:低档，2:中档，3:高档；
  7. shopping_level：购物深度，1:浅层用户,2:中度用户,3:深度用户
  8. occupation：是否大学生 ，1:是,0:否
  9. new_user_class_level：城市层级

- 用户的行为日志behavior_log

  本数据集涵盖了raw_sample中全部用户22天内的购物行为(共七亿条记录)。字段说明如下：

  user：脱敏过的用户ID；
  time_stamp：时间戳；
  btag：行为类型, 包括以下四种：
  ​	类型 | 说明
  ​	pv | 浏览
  ​	cart | 加入购物车
  ​	fav | 喜欢
  ​	buy | 购买
  cate_id：脱敏过的商品类目id；
  brand_id: 脱敏过的品牌id；
  这里以user + time_stamp为key，会有很多重复的记录；这是因为我们的不同的类型的行为数据是不同部门记录的，在打包到一起的时候，实际上会有小的偏差（即两个一样的time_stamp实际上是差异比较小的两个时间）

## 2 项目实现

### 2.1 处理原始表中的数据

#### (1) **原始样本骨架raw_sample**

用户id、广告id、广告资源位pid、点击clk和不点击noclk、时间戳

* 这份数据集的目标是 点不点击（clk and noclk），特征是**广告资源位pid**（两种，比值=6:4)。

* 对pid进行独热编码
* 依据时间戳，将数据集划分为训练集和测试集

**涉及的技术**：

* spark的独热编码、稀疏向量
* 时间戳如何转换成datetime格式



#### (2) **广告基本信息表ad_feature**

广告id=商品id	商品价格price	商品类目id	商品品牌id	广告计划id	广告主id

* 仅保留商品**价格price**作特征数据：后四个特征分类太多，不适合做独热编码；且它们仅有id号，没有更多信息

**涉及的技术**：

* sparksql中dropna删空值
* sparksql改变表字段的数据类型



#### (3)**用户基本信息表user_profile**

用户id	用户性别	用户年龄层级1234	消费档次	购物深度	是否大学生	城市层级	微群id	cms_group_id

* 消费档次p_level和城市层级new_user_class_level两列数据有缺失，处理方案：确实值字段映射高维空间
* 该表**所有信息**都可作为用户特征

**涉及的技术**：

* 缺失值的处理方案：
  * 填充方案：结合用户的其他特征值，利用随机森林算法进行预测；但产生了大量人为构建的数据，一定程度上增加了数据的噪音
  * 把变量映射到高维空间：如pvalue_level的1维数据，转换成是否1、是否2、是否3、是否缺失的4维数据；这样保证了所有原始数据不变，同时能提高精确度，但这样会导致数据变得比较稀疏，如果样本量很小，反而会导致样本效果较差，因此也不能滥用

* spark如何使用随机森林分类模型，并填补数据。
* 如何将填补的数据和没有缺失值的数据拼成一张表。
* LabeledPoint 与 稀疏矩阵SparseVector。



#### (4) **用户的行为日志behavior_log**  

用户id	商品类目id	商品品牌id	行为(btag)：浏览、加入购物车、喜欢、购买	时间戳	

原始表->两张表(见下)->训练ALS模型，进而为每个用户推荐3个商品种类（->存到redis中）和3个品牌

​			1. **用户id-商品类目id->行为**  转为  **用户id->商品类目id->四种行为**  转为 **用户id-商品类目id->评分**

​			2. **用户id-商品品牌id->行为**  转为  **用户id->商品品牌id->四种行为**  转为 **用户id-商品品牌id->评分**

**涉及的技术**：

* spark中如何制作透视表pivot

* spark中如何使用ALS模型，如何根据模型为用户推荐商品。



### 2.2 **获取计算点击率的CTR模型**：

* raw_sample表**广告位pid** + ad_feature表**price** + user_profile表**所有信息** ==> **LR模型** ==> 点击率
* 将以上所有特征合并成一张表，划分训练集（前7天数据）、测试集（第八天数据），训练得到两种模型：
  * 训练CTRModel_Normal：直接将对应特征 的特征值  组合成  对应的特征向量，进行训练
  * 训练CTRModel_AllOneHot：更优
* 非搜索广告（例如展示广告，信息流广告）的点击率的计算很多就来源于用户的兴趣和广告自身的特征，以及上下文环境。通常**好位置能达到百分之几的点击率**。对于很多**底部的广告，点击率非常低，常常是千分之几**，甚至更低

**涉及的技术**：

* 多种特征向量集成一个向量，VectorAssembler



### 2.3 离线数据缓存

#### (1) **离线数据缓存之离线召回集**：

* 使用上面得到的**用户id-商品类目id->评分** 表和spark中的ALS模型==>每个用户对每个种类的预测评分 => 为每个用户推荐感兴趣的3个类别，再从这3个类别中半随机地选出500个商品**作为召回集，保存到redis中**；模型保存到hdfs

涉及的技术：

* redis的使用

#### (2) **离线数据缓存之离线特征**：

* 缓存用户和广告的离线特征到redis中，用于接下来的实时推荐
* 上面的离线召回集，已经为每个用户缓存了500个商品，这些商品是从最感兴趣的类别中随机选的
* 召回集中商品的离线特征 + 用户的特征 ==> 利用LR算出点击率，再排序。

**涉及的技术**：

* json的格式

### 2.4 实时日志分析与推荐

#### (1) **实时日志行为处理**：

假设日志格式为："时间,地点,用户ID,商品ID,类别ID,品牌ID,商品价格"

* 根据实时的用户日志行为做出相应的反馈：**实时更新特征、实时更新召回集**
* 提出日志中有用的数据：
  * 对用户的基本信息产生影响的数据：**地点(根据当前低点定位来判断用户的消费环境/等级)、购买行为的商品价格**，这些特征放入 redis该用户对应的离线特征集中。
  * 对用户召回结果产生影响的数据：**商品的类别、品牌**，用户刚刚购买了某商品，就提取该商品的类别和品牌信息 ==> 从该类和该品牌的商品中，随机抽出50个商品，放入 该用户对应的召回集中，我称之为在线召回

**涉及的技术**：

* kafka

#### (2) **实时推荐任务处理**：

召回集（离线召回+在线召回）中物品 = => CTR预测模型+特征==>预测结果 => TOP-N列表

- CTR预测模型在离线阶段已经训练完成，此处仅需**加载**
- 特征是：用户实时特征 + （该用户对应的）召回集（离线召回+在线召回）中物品的特征
  - 我说的在线召回：用户刚买了某个种类的物品，就随机取出 该类中 若干个物品，放入召回集中
- 预测结果：计算出点击率，排序，得到，例如为某用户推荐top20物品

### 2.5 项目中使用到的技术

Flume、Kafka、Spark-streming\HDFS、Spark SQL、Spark ML、Redis

- Flume：日志数据收集。暂无
- Kafka：实时日志数据处理队列
- HDFS：存储数据
- Spark SQL：离线处理
- Spark ML：模型训练
- Redis：缓存



## 3 项目效果展示

![image-20210312224748835](%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0.assets/项目效果展示.png)

