{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实时推荐\n",
    "\n",
    "网站初期，在没有排序模型情况下，可直接根据商品的相似度，找出用户当前正在发生行为的商品  的相似商品进行推荐(在线召回)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 配置pyspark和spark driver运行时 使用的python解释器\n",
    "JAVA_HOME = '/root/bigdata/jdk'\n",
    "PYSPARK_PYTHON = '/miniconda2/envs/py365/bin/python'\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ['PYSPARK_PYTHON'] = PYSPARK_PYTHON\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = PYSPARK_PYTHON\n",
    "os.environ['JAVA_HOME'] = JAVA_HOME\n",
    "# 注意，如果是使用jupyter或ipython中，利用spark streaming链接kafka的话，必须加上下面语句\n",
    "# 同时注意：spark version>2.2.2的话，pyspark中的kafka对应模块已被遗弃，因此这里暂时只能用2.2.2版本的spark\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.2 pyspark-shell\"\n",
    "# 配置spark信息\n",
    "from pyspark import SparkConf\n",
    "import pyspark\n",
    "\n",
    "SPARK_APP_NAME = \"meiduo_logs\"\n",
    "SPARK_URL = \"spark://192.168.58.100:7077\"\n",
    "\n",
    "conf = SparkConf()    # 创建spark config对象\n",
    "config = (\n",
    "\t(\"spark.app.name\", SPARK_APP_NAME),    # 设置启动的spark的app名称，没有提供，将随机产生一个名称\n",
    "\t(\"spark.executor.memory\", \"2g\"),    # 设置该app启动时占用的内存用量，默认1g，指一台虚拟机\n",
    "\t(\"spark.master\", SPARK_URL),    # spark master的地址\n",
    "    (\"spark.executor.cores\", \"2\"),    # 设置spark executor使用的CPU核心数，指一台虚拟机\n",
    "#     (\"hive.metastore.uris\", \"thrift://localhost:9083\"),    # 配置hive元数据的访问，否则spark无法获取hive中已存储的数据\n",
    "    \n",
    "    # 以下三项配置，可以控制执行器数量\n",
    "#     (\"spark.dynamicAllocation.enabled\", True),\n",
    "#     (\"spark.dynamicAllocation.initialExecutors\", 1),    # 1个执行器\n",
    "#     (\"spark.shuffle.service.enabled\", True)\n",
    "# \t('spark.sql.pivotMaxValues', '99999'),  # 当需要pivot DF，且值很多时，需要修改，默认是10000\n",
    ")\n",
    "# 查看更详细配置及说明：https://spark.apache.org/docs/latest/configuration.html\n",
    "\n",
    "conf.setAll(config)\n",
    "\n",
    "# 利用config对象，创建spark session\n",
    "sc = pyspark.SparkContext(master=SPARK_URL, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意：初次安装并运行时，由于使用了kafka，所以会自动下载一系列的依赖jar包，会耗费一定时间\n",
    "\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# 第2个参数表示 程序运行间隔时间\n",
    "ssc = StreamingContext(sc, 0.5)\n",
    "\n",
    "kafkaParams = {\"metadata.broker.list\": \"192.168.58.100:9092\"}\n",
    "dstream = KafkaUtils.createDirectStream(ssc, [\"meiduo_click_trace\"], kafkaParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意row[1]是什么意思？\n",
    "以下段代码为例：\n",
    "```\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# 第2个参数表示 程序运行间隔时间\n",
    "ssc = StreamingContext(sc, 0.5)\n",
    "\n",
    "kafkaParams = {\"metadata.broker.list\": \"192.168.58.100:9092\"}\n",
    "dstream = KafkaUtils.createDirectStream(ssc, [\"meiduo_click_trace\"], kafkaParams)\n",
    "def preprocessing(row):\n",
    "    return row[1]\n",
    "def foreachRDD(rdd):\n",
    "    print(\"foreachRDD\", rdd.collect())\n",
    "dstream.map(preprocessing).foreachRDD(foreachRDD)\n",
    "\n",
    "ssc.start()\n",
    "```\n",
    "无论使用row还是row[1]，结果是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing(row):\n",
    "    match = re.search(\"\\\n",
    "exposure_timesteamp<(?P<exposure_timesteamp>.*?)> \\\n",
    "exposure_loc<(?P<exposure_loc>.*?)> \\\n",
    "timesteamp<(?P<timesteamp>.*?)> \\\n",
    "behavior<(?P<behavior>.*?)> \\\n",
    "uid<(?P<uid>.*?)> \\\n",
    "sku_id<(?P<sku_id>.*?)> \\\n",
    "cate_id<(?P<cate_id>.*?)> \\\n",
    "stay_time<(?P<stay_time>.*?)>\", row[1])\n",
    "\n",
    "    result = []\n",
    "    if match:\n",
    "        result.append((\"exposure_timesteamp\", match.group(\"exposure_timesteamp\")))\n",
    "        result.append((\"exposure_loc\", match.group(\"exposure_loc\")))\n",
    "        result.append((\"timesteamp\", match.group(\"timesteamp\")))\n",
    "        result.append((\"behavior\", match.group(\"behavior\")))\n",
    "        result.append((\"uid\", match.group(\"uid\")))\n",
    "        result.append((\"sku_id\", match.group(\"sku_id\")))\n",
    "        result.append((\"cate_id\", match.group(\"cate_id\")))\n",
    "        result.append((\"stay_time\", match.group(\"stay_time\")))\n",
    "    return result #得到用户实时点击结果\n",
    "\n",
    "import redis\n",
    "client0 = redis.StrictRedis(db=0)    # 此前redis 0号库中已经存储了每个商品的TOP-N个相似商品\n",
    "client1 = redis.StrictRedis(db=1)\n",
    "\n",
    "# 根据实时点击的日志->取出uid和sku_id->根据这两个id，去redis中找到对应的相似物品\n",
    "def foreachRDD(rdd):\n",
    "    # 网站初期，在没有排序模型情况下，可直接根据商品的相似度，找出用户当前正在发生行为商品的相似商品进行推荐(在线召回)\n",
    "    for data in rdd.collect():\n",
    "        # 你忘了吗？python 字典的生成\n",
    "        # test1=[('ni',1),('hao',2),('ma',3)]\n",
    "        # test2=dict(test1)\n",
    "        # test2\n",
    "        # {'ni': 1, 'hao': 2, 'ma': 3}\n",
    "        data = dict(data)\n",
    "        sku_id = data.get(\"sku_id\")\n",
    "        uid = data.get(\"uid\")\n",
    "        \n",
    "        sim_skus = client0.zrevrange(sku_id, 0,4) # 取出最相似的前5个\n",
    "        client1.sadd(uid, *sim_skus)    # 放入用户的召回集中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstream.map(preprocessing).foreachRDD(foreachRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一条点击流日志，比如用户1浏览(pv)了 商品sku_id=19,返回5个与sku_id最相似的商品 \n",
    "import logging#log：记录\n",
    "import time\n",
    "\n",
    "def get_logger(logger_name, path, level):\n",
    "    \n",
    "    # 创建logger\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # level:  OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自己定义的级别\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    # 创建formatter\n",
    "    # %(asctime)s: 打印日志的时间\n",
    "    # %(message)s: 打印日志信息\n",
    "    fmt = '%(asctime)s: %(message)s'\n",
    "    datefmt = '%Y/%m/%d %H:%M:%S'\n",
    "    formatter = logging.Formatter(fmt,datefmt)\n",
    "\n",
    "    # 创建handler\n",
    "    # FileHandler：writes formatted logging records to disk files\n",
    "    handler = logging.FileHandler(path)\n",
    "    handler.setLevel(level)\n",
    "\n",
    "    # 添加handler和formatter 到 logger\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "click_trace_logger = get_logger('click_trace','/root/workspace/3.rs_project/project2/meiduoSourceCode/logs/click_trace.log',\\\n",
    "                               logging.DEBUG)\n",
    "\n",
    "# 点击流日志\n",
    "exposure_timesteamp = time.time()\n",
    "exposure_loc = 'detail'\n",
    "timesteamp = time.time()\n",
    "behavior = 'pv' # pv|浏览 cart|加入购物车 fav|喜爱 buy|购买\n",
    "uid = 4\n",
    "sku_id = 26\n",
    "cate_id = 1\n",
    "stay_time = 60\n",
    "# # 假设某点击流日志记录格式如下：\n",
    "click_trace_logger.info(\"exposure_timesteamp<%d> exposure_loc<%s> timesteamp<%d> behavior<%s> uid<%d> sku_id<%d> cate_id<%d> stay_time<%d>\"\\\n",
    "                        %(exposure_timesteamp, exposure_loc, timesteamp, behavior, uid, sku_id, cate_id, stay_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你忘了吗？python 字典的生成\n",
    "# test1=[('ni',1),('hao',2),('ma',3)]\n",
    "# test2=dict(test1)\n",
    "# test2\n",
    "# {'ni': 1, 'hao': 2, 'ma': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但当网站运行一段时间后，已经收集了大量的用户行为数据以后，那么在离线处理中，就可以训练出相关排序模型(点击率预测、跳出率预测、转化率预测)。由于离线推荐主要以T+1形式推荐，因此在线推荐就还需要对用户今日的行为进行统计分析，得出用户今日的实时兴趣作为用户的实时画像，**供排序模型使用**\n",
    "\n",
    "今天之前是一个 T单位的数据,新加一天就是（T + 1）单位的数据。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
