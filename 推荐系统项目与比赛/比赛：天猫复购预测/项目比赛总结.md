## 一、 天池大赛：天猫复购预测之挑战baseline

https://tianchi.aliyun.com/competition/entrance/231576/information

用户画像：user_id、age_range（离散特征，0和NULL表示未知，因此空值使用0填充）、gender（2和NULL表示未知，因此空值使用2填充）

用户的行为日志：user_id、商家id编码、商品的唯一编码、商品所属品类的唯一编码、商品品牌的唯一编码、timestamp购买时间（格式：mmdd）、行为类型（包含{0, 1, 2, 3}，0表示单击，1表示添加到购物车，2表示购买，3表示添加到收藏夹）

### 1. 数据预处理

1.1 缺失值填充见上

1.2 数据类型转换 astype

### 2. 特征工程

#### 2.1 用户特征构造

按照user_id聚合`groupby(['user_id'])`，`merge`

新增数列：多少种商品id、多少种商品品类id、多少种商家id、多少种商品品牌id、该用户首末两次行为的时间差（h）、每种action的个数（共4种action）、每个用户的购买点击比（根据前一个字段的统计数据计算）

#### 2.2 商家特征构造

同用户特征类似的构造方法+每个商家的负采样数量（负采样即每个商家对应的label=-1的数量，-1表示'user_id'不是给定商家的新客户）

#### 2.3 “用户-商家”特征构造

以“用户-商家”为对象，`groupby(['user_id', 'merchant_id'])`

每个对象交互的item_id的种类数量、每个对象交互的cat_id 的种类数量、每个对象交互的brand_id 的种类数量、每个对象 四种行为的个数（即该对象对应的点击了几次，购买了几次，...）、每个对象(最后一次行为记录时间 - 第一次行为记录时间)的小时差、每个对象的购买点击比 

#### 2.4  特征构造后的缺失值填充

`fillna(0, inplace=True)`

#### 2.5 类别型特征onehot编码(可选)

性别和年龄是类别型特征，`get_dummies(某列,prefix='age')`

#### 2.6 数据型特征normalize（可选）

逻辑回归、随机森林、NFM、deepfm（标准化）使用

XGB们不需要

### 3. 训练模型

#### 3.1 划分数据集

对比两种训练方式：第一种方式-测试集、训练集按照比列（0.2）随机划分；第二种方式-skfold（k折）交叉验证

#### 3.2 不同模型系训练调参情况

（1）逻辑回归、随机森林：样本特征中去掉user_id、merchant_id两列，得分更高；非5折情况下LR 0.640，随机森林0.6461（200棵树，100棵树是0.63），5折均稍高；

（2）svm：`model_svm = SVC(probability=True)`，google colab TPU训练12小时仍未完成训练。

（3）XGBoost、LightGBM、Catboost：auc > 0.68；保留user_id、merchant_id两列特征，auc得分更高；是否5折交叉=>LGB交叉验证auc大=>三种交叉验证的模型预测结果 融合=>不融合、skfold LGB最好

（4）Deepfm、NFM：batch_size(128, 256, 500, 1000)，epoch(10, 20, 50)，学习率、dnn_hidden(default 128X128, 3X128, 3X200) 、dropout， 最优 0.6563

（5）DIN：效果不好

（6）各种模型融合

### 4. 总结

- 数据处理工作在myxgboost中，最终得到matrix
- 最好的结果：0.95* skfold五折交叉验证的随机森林 + 0.05* skold五折交叉验证的lightgbm。都是5折
- 最好结果：0.6840272

![image-20210524162457527](%E9%A1%B9%E7%9B%AE%E6%AF%94%E8%B5%9B%E6%80%BB%E7%BB%93.assets/image-20210524162457527.png)

## 二、天池大赛：二手车交易价格预测

https://tianchi.aliyun.com/competition/entrance/231784/information

### 1. 数据预处理

#### 1.1 连续性特征长尾分布处理

取log，最后结果要exp还原，`np.log1p(train_data['price'])`

#### 1.2 缺失值填充

缺失比例：3%、5.8%、3.9%、1/50000，都是类别型

分类太多的特征用众数填充：`df.model.fillna(df.model.mode()[0],inplace=True)`

分类不多的特征用-1填充：`df[col].fillna(-1,inplace=True) `

有些缺失值是隐藏的，比如 '-'，使用-1替代，`df['notRepairedDamage'].replace('-','-1',inplace=True)`

#### 1.3 异常值处理

题目限制功率不大于600，`df['power'] = df['power'].map(lambda x: 600 if x>600 else x) #限定power<=600`

#### 1.4 连续值分桶

```python
# 对可分类的连续特征进行分桶，kilometer是已经分桶了
bin = [-1]+[i*10 for i in range(1,61)]
df['power_bin'] = pd.cut(df['power'], bin, labels=False)
bin = [-1]+[i*10 for i in range(1,26)]
df['model_bin'] = pd.cut(df['model'], bin, labels=False)
# model: 车型编码，已脱敏
```

### 2. 特征构造

#### 2.1 时间特征提取

汽车注册时间和上线时间（即开始售卖时间）的年、月、日；二手车已被使用的天数、年数

#### 2.2 聚合特征

车的品牌、车型编码、已行驶公里、燃油类型、车身类型分别聚合`groupby`，然后再分别对功率、使用天数`agg`求 最值、中位数、标准差、平均值、个数

#### 2.3 特征构造完成后产生的缺失值-众数填补

### 3. 特征筛选

#### 3.1 删除无用特征

#### 3.2 删除相关性大的特征

计算各特征之间的相关性，画出热力图，相关性为1的比删除一个，大于0.9的此题也删除。

### 4. 模型训练

MAE

随机划分（0.2）训练、测试集

（1）xgboost、lgbm：xgb 643，lgb590；模型融合：全量的数据输入模型得到MAE

```python
predict_y = (1-MAE_lgb/(MAE_xgb+MAE_lgb))*result_lgb + (1-MAE_xgb/(MAE_xgb+MAE_lgb))*result_xgb
```

（2）NN model：

* 特征数据minmaxscaler还是标准化对比，后者好的挺多。
* 选择不同的特征列；对比删除相关性大的特征前后的效果
* 调参-神经元个数（150,250,300,500）、加层、batch_size(128,256,500,1000)、epoch(10,20,50,150)、是否Batch Normalization；10折交叉验证

```python
# 搭建模型
model = keras.Sequential([
    #全连接层：`tf.keras.layers.Dense(神经元个数，activation= "激活函数“，kernel_regularizer=哪种正则化)`
    # 输入的维度是特征的维度
    keras.layers.Dense(250, activation='relu',input_shape=[len(tags)]),
    keras.layers.Dense(250, activation='relu'),
    keras.layers.Dense(250, activation='relu'),
#     keras.layers.BatchNormalization(),
    # If you don't specify anything, no activation is applied
    keras.layers.Dense(1)
])
# 定义损失函数，优化器
model.compile(loss='mean_absolute_error',optimizer='Adam')
# 模型训练
model.fit(train_x,train_y,batch_size=500,epochs=150)
```

（3）模型融合：lxgb + NN，不同比例

### 5.  总结

```python
# 最优的提交结果  online test: 433.9189
res_lxgb_kfnn['price'] = res_kfnn['price']*0.95 + res_lxgb['price']*0.05
```

![image-20210524172519374](%E9%A1%B9%E7%9B%AE%E6%AF%94%E8%B5%9B%E6%80%BB%E7%BB%93.assets/image-20210524172519374.png)

